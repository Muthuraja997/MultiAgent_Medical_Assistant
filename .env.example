# ============================================================================
# Multi-Agent Medical Assistant - Environment Configuration
# ============================================================================
# 
# This file shows all available environment variables.
# 
# Copy to `.env` and fill with your actual values:
#   cp .env.example .env
#
# IMPORTANT: Choose ONE setup option:
#   1. Cloud Setup (Azure OpenAI) - All variables required
#   2. Open-Source Setup (Ollama) - Leave cloud keys empty, modify config.py
#   3. Hybrid Setup - Cloud LLM + Local Vector DB
#
# See SETUP_GUIDE.md for detailed instructions
# ============================================================================

# ============================================================================
# REQUIRED FOR ALL SETUPS
# ============================================================================

# FastAPI Server Settings
HOST=0.0.0.0
PORT=8000
DEBUG=True

# ============================================================================
# SETUP OPTION A: CLOUD-BASED (Azure OpenAI + Qdrant)
# ============================================================================
# Fill these if using Azure OpenAI for LLM and embeddings

# --- Azure OpenAI LLM Configuration ---
# Get these from: https://portal.azure.com/
deployment_name=gpt-4o-deployment
model_name=gpt-4o
azure_endpoint=https://your-resource.openai.azure.com/
openai_api_key=your-azure-openai-api-key
openai_api_version=2024-05-01

# --- Azure OpenAI Embeddings Configuration ---
# Separate Azure OpenAI instance for embeddings (optional, can be same as above)
embedding_deployment_name=text-embedding-3-large-deployment
embedding_model_name=text-embedding-3-large
embedding_azure_endpoint=https://your-resource.openai.azure.com/
embedding_openai_api_key=your-embedding-api-key
embedding_openai_api_version=2024-05-01

# ============================================================================
# SETUP OPTION B: OPEN-SOURCE (Ollama)
# ============================================================================
# Leave Azure keys empty above and follow instructions in SETUP_GUIDE.md
# 
# Steps:
# 1. Install Ollama: https://ollama.ai
# 2. Run: ollama serve
# 3. Modify config.py to use OllamaLLM instead of AzureChatOpenAI
# 4. Models to pull: mistral, neural-chat, or llama2
#
# Example in config.py:
#   from langchain_ollama import OllamaLLM
#   self.llm = OllamaLLM(model="mistral", base_url="http://localhost:11434")

# ============================================================================
# OPTIONAL: WEB SEARCH AGENT
# ============================================================================

# Option 1: Cloud-based web search (requires API key)
# Get from: https://tavily.com/
TAVILY_API_KEY=your-tavily-api-key

# Option 2: Open-source (use DuckDuckGo - no key needed)
# See SETUP_GUIDE.md for DuckDuckGo setup instructions
# Just comment out TAVILY_API_KEY above

# ============================================================================
# OPTIONAL: SPEECH PROCESSING (Text-to-Speech & Speech-to-Text)
# ============================================================================

# Option 1: Cloud-based speech (requires API key)
# Get from: https://elevenlabs.io/
ELEVEN_LABS_API_KEY=your-elevenlabs-api-key

# Option 2: Open-source (pyttsx3, Vosk, or Whisper - no key needed)
# See SETUP_GUIDE.md for open-source speech setup
# Just comment out ELEVEN_LABS_API_KEY above

# ============================================================================
# OPTIONAL: QDRANT VECTOR DATABASE
# ============================================================================

# By default, uses local Qdrant at ./data/qdrant_db/
# No configuration needed for local setup.

# For Qdrant Cloud (optional, remote storage):
# Get from: https://cloud.qdrant.io/
# QDRANT_URL=https://your-qdrant-url.qdrant.io:6333
# QDRANT_API_KEY=your-qdrant-api-key

# ============================================================================
# ADVANCED CONFIGURATION (Optional)
# ============================================================================

# HuggingFace Token (Optional - for downloading free models)
# Get from: https://huggingface.co/settings/tokens
# Used for: Embeddings, reranking, and other NLP models
# Cost: FREE - All models used are open-source and free
# See: HUGGINGFACE_GUIDE.md for model details
HUGGINGFACE_TOKEN=your-huggingface-token-here

# Logging level
LOG_LEVEL=INFO

# RAG Configuration
RAG_CHUNK_SIZE=512
RAG_CHUNK_OVERLAP=50
RAG_MIN_CONFIDENCE=0.40

# Conversation history limit (number of messages)
MAX_CONVERSATION_HISTORY=20

# API Rate Limiting
RATE_LIMIT=10

# Maximum image upload size (MB)
MAX_IMAGE_UPLOAD_SIZE=5

# ============================================================================
# QUICK START EXAMPLES
# ============================================================================

# Example 1: Minimal Cloud Setup (Just Azure OpenAI)
# -------
# deployment_name=gpt-4o-deployment
# model_name=gpt-4o
# azure_endpoint=https://your-resource.openai.azure.com/
# openai_api_key=sk-...
# openai_api_version=2024-05-01
# embedding_deployment_name=text-embedding-3-large-deployment
# embedding_model_name=text-embedding-3-large
# embedding_azure_endpoint=https://your-resource.openai.azure.com/
# embedding_openai_api_key=sk-...
# embedding_openai_api_version=2024-05-01

# Example 2: Open-Source Local Setup (Nothing required here!)
# -------
# All keys can be empty - make sure to:
# 1. Install Ollama
# 2. Run: ollama pull mistral
# 3. Run: ollama serve
# 4. Modify config.py as shown in SETUP_GUIDE.md

# Example 3: Hybrid Setup (Azure LLM + Local Vector DB)
# -------
# deployment_name=gpt-4o-deployment
# model_name=gpt-4o
# azure_endpoint=https://your-resource.openai.azure.com/
# openai_api_key=sk-...
# openai_api_version=2024-05-01
# embedding_deployment_name=text-embedding-3-large-deployment
# embedding_model_name=text-embedding-3-large
# embedding_azure_endpoint=https://your-resource.openai.azure.com/
# embedding_openai_api_key=sk-...
# embedding_openai_api_version=2024-05-01
# (Qdrant uses local ./data/qdrant_db/ by default)
# (Skip Tavily and ElevenLabs for optional features)

# ============================================================================
# TESTING YOUR SETUP
# ============================================================================
#
# After creating .env file, test with:
#
#   python test_llm.py           # Test LLM connection
#   python test_qdrant.py        # Test vector database
#   python test_embeddings.py    # Test embeddings
#
# Then start the server:
#
#   python app.py
#
# Access at: http://localhost:8000

# ============================================================================
# NOTES
# ============================================================================
# 
# - Do NOT commit this file if you fill in real API keys
# - Use different API keys for dev/staging/production
# - Rotate API keys regularly for security
# - Monitor Azure usage to avoid unexpected charges
# - For production, use environment variables instead of .env file
# - See SETUP_GUIDE.md for troubleshooting and comparisons
#
# ============================================================================
